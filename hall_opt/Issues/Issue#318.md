
### Explanation:

#### main.py (simplified)
```
from hall_opt.utils.data_loader import get_ground_truth_data
from hall_opt.scripts.map import run_map_workflow
from hall_opt.scripts.gen_data import generate_ground_truth

def main():
    ...
    # Step 1: Generate or Load Ground Truth
    observed_data, metrics = get_ground_truth_data(settings)

    if observed_data is None:
        print("[FATAL] No ground truth available. Exiting.")
        sys.exit(1)

    # Step 2: Pass data into MAP
    if settings.run_map:
        run_map_workflow(observed_data, settings)
```
And then inside get_ground_truth_data(settings):
```
def get_ground_truth_data(settings):
    if settings.gen_data:
        print("[INFO] Generating ground truth...")
        observed_data = generate_ground_truth(settings)
        return observed_data, observed_data  # also returns metrics
    ...
```
How the data generated by `gen_data=True` gets passed directly into `run_map_workflow()` from `main.py`. The MAP workflow is kept modular and doesn't generate data itself — instead, main() handle integration, and observed_data is injected into both MAP and MCMC steps.


#### Alternative: Using an external file for gen_data (i.e. use pre-generated or external ground truth instead of running the simulator).

Point the yaml to your desired file using the reference_data field in the YAML:
```yaml
	output_dir: "results_map"
	run_map: true
	gen_data: false  # do NOT regenerate
	reference_data: "my_custom_data/ground_truth.json"
```
When `gen_data: false`, the pipeline will look at `settings.reference_data`. If it’s a `.json` or `.csv` file, it will attempt to load it and pass it into `run_map_workflow()` automatically.
 